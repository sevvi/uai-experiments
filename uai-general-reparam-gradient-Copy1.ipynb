{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import argparse, gzip, cPickle, sys, time, itertools\n",
    "\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.norm as norm\n",
    "import autograd.scipy.stats.dirichlet as dirichlet\n",
    "from autograd.scipy.misc import logsumexp\n",
    "from autograd.util import flatten_func, flatten\n",
    "from autograd import grad, primitive\n",
    "from autograd.numpy.numpy_grads import unbroadcast\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import mixture\n",
    "\n",
    "from  autograd.scipy.special import gammaln, digamma, gamma\n",
    "from scipy import linalg\n",
    "from scipy import stats, integrate\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "color_names = [\"windows blue\",\n",
    "               \"red\",\n",
    "               \"gold\",\n",
    "               \"grass green\"]\n",
    "colors = sns.xkcd_palette(color_names)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "class Adam(object):\n",
    "    def __init__(self, dparam, learning_rate=0.001, b1=0.9, b2=0.999, eps=10**-8,\n",
    "                         decay_rate = 0.9, decay_steps = 100):                    \n",
    "        self.b1 = b1;\n",
    "        self.b2 = b2;\n",
    "        self.eps = eps\n",
    "        self.learning_rate = learning_rate        \n",
    "        self.m = np.zeros(dparam)\n",
    "        self.v = np.zeros(dparam)\n",
    "        self.i = 0\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "    \n",
    "    def step(self, gradients):        \n",
    "        self.i = self.i+1\n",
    "        step_size = self.learning_rate * self.decay_rate**(self.i/self.decay_steps)\n",
    "        self.m = (1 - self.b1) * gradients + self.b1 * self.m\n",
    "        self.v = (1 - self.b2) * (gradients**2) + self.b2 * self.v\n",
    "        mhat = self.m / (1 - self.b1**(self.i))\n",
    "        vhat = self.v / (1 - self.b2**(self.i))        \n",
    "        step = step_size*mhat/(np.sqrt(vhat) + self.eps)        \n",
    "        return step\n",
    "\n",
    "    \n",
    "@primitive\n",
    "def softplus(x):\n",
    "    return np.log(1. + np.exp(x))\n",
    "\n",
    "softplus.defvjp(lambda g, ans, vs, gvs, x: unbroadcast(vs, gvs, g * 1./(1. + np.exp(-x))))\n",
    "\n",
    "def jacobian_softplus(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "@primitive\n",
    "def gamma_logpdf(x, alpha = 1., beta = 1.):\n",
    "    return  (alpha*np.log(beta) + (alpha - 1)*np.log(x) - x*beta - gammaln(alpha))\n",
    "\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs, g * ((alpha-1)/x - beta)))\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs,  g * (np.log(beta) + np.log(x) - digamma(alpha))), argnum=1)\n",
    "gamma_logpdf.defvjp(lambda g, ans, vs, gvs, x, alpha=1.0, beta=1.0: unbroadcast(vs, gvs,  g * (alpha/beta - x)), argnum=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Normal(object):\n",
    "    def __init__(self, data, scale = 1.):\n",
    "        self.data = data     \n",
    "        self.scale = scale\n",
    "        self.N = data.shape[0]\n",
    "        self.D = data.shape[1]\n",
    "    \n",
    "    def p_log_prob(self, idx, z):\n",
    "        x = self.data\n",
    "        mu, tau = z['mu'], softplus(z['tau'])\n",
    "        log_prior = 0.\n",
    "        log_prior = np.sum(gamma_logpdf(tau, 1e-3, 1e-3)) + np.sum(np.log(jacobian_softplus(z['tau'])))\n",
    "        log_prior += np.sum(norm.logpdf(mu, 0., 1/np.sqrt(tau)))        \n",
    "        log_lik = np.sum(norm.logpdf(x, mu, 1/np.sqrt(tau)))\n",
    "        return self.scale * log_lik + log_prior\n",
    "    \n",
    "    def q_log_prob(self, params, z):\n",
    "        q_mean = np.sum(norm.logpdf(z['mu'], params['mu']['mean'], np.exp(params['mu']['sigma'])))\n",
    "        q_sigma = np.sum(norm.logpdf(z['tau'], params['tau']['mean'], np.exp(params['tau']['sigma'])))        \n",
    "        return q_mean + q_sigma\n",
    "      \n",
    "    def q_log_prob_sep(self, params, z):\n",
    "        q_mean = norm.logpdf(z['mu'], params['mu']['mean'], np.exp(params['mu']['sigma']))\n",
    "        q_sigma = norm.logpdf(z['tau'], params['tau']['mean'], np.exp(params['tau']['sigma']))\n",
    "        return np.concatenate(q_mean, q_sigma)\n",
    "    \n",
    "    def sample_q(self, params):\n",
    "        sample = {}\n",
    "        eps = {}        \n",
    "        eps['mu'] = npr.randn(len(params['mu']['mean']))\n",
    "        eps['tau'] = npr.randn(len(params['tau']['mean']))        \n",
    "        q_mu_s = np.exp(params['mu']['sigma']) * eps['mu'] + params['mu']['mean'] \n",
    "        q_tau_s = np.exp(params['tau']['sigma']) * eps['tau'] + params['tau']['mean'] \n",
    "        sample['mu'] = q_mu_s        \n",
    "        sample['tau'] = q_tau_s\n",
    "        return (sample, eps)\n",
    "    \n",
    "    def grad_p(self, dp_log_prob, eps, params, w = 1.):        \n",
    "        dp_log_prob_ = {'mu': {}, 'tau': {}}\n",
    "        dp_log_prob_['mu']['mean'] = w * dp_log_prob['mu']\n",
    "        dp_log_prob_['mu']['sigma'] = w * dp_log_prob['mu']*eps['mu']*np.exp(params['mu']['sigma']) + 1\n",
    "        \n",
    "        dp_log_prob_['tau']['mean'] = w * dp_log_prob['tau']\n",
    "        dp_log_prob_['tau']['sigma'] = w * dp_log_prob['tau']*eps['tau']*np.exp(params['tau']['sigma']) + 1                \n",
    "        return dp_log_prob_\n",
    "    \n",
    "    def calc_eps(self, z, params):\n",
    "        sample = {}\n",
    "        eps = {}                \n",
    "        eps['mu']  = (z['mu'] - params['mu']['mean']) / np.exp(params['mu']['sigma'])  \n",
    "        eps['tau']  = (z['tau'] - params['tau']['mean']) / np.exp(params['tau']['sigma'])          \n",
    "        return eps            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Inference(object):      \n",
    "    def __init__(self, model, params):\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "\n",
    "    def run(self, epochs, batch_size, samples, learning_rate, algorithm = 'SGD', optimizer = 'adam'):\n",
    "        self.epochs = epochs\n",
    "        self.batches = self.model.N/batch_size\n",
    "        self.batch_size = batch_size\n",
    "        self.samples = samples\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        fparams, unflatten = flatten(self.params)\n",
    "        self.D =len(fparams)\n",
    "\n",
    "        self.loss = 0.\n",
    "        self.F = np.zeros(self.epochs * self.batches)\n",
    "        self.time = np.zeros(self.epochs * self.batches)\n",
    "        self.n = 1\n",
    "        adam = Adam(self.D, learning_rate = learning_rate)        \n",
    "        f = 0\n",
    "        \n",
    "        grad_p_log_prob = grad(model.p_log_prob, argnum = 1)\n",
    "        grad_q_log_prob = grad(model.q_log_prob, argnum = 1)\n",
    "        \n",
    "        if algorithm == 'SGD':\n",
    "            for e in range(self.epochs):\n",
    "                for b in range(self.batches): \n",
    "                    start = time.clock()\n",
    "                    losses = 0.\n",
    "                    d_elbo = 0.\n",
    "                    idx = 0\n",
    "                    d_elbo = 0.\n",
    "\n",
    "                    params = unflatten(fparams)                \n",
    "                    for s in range(self.samples):\n",
    "                        z, eps = model.sample_q(params)\n",
    "                        p_log_prob = model.p_log_prob(idx, z)\n",
    "                        g,_ =  flatten(model.grad_p(grad_p_log_prob(idx, z), eps, params))\n",
    "                        d_elbo += g\n",
    "                        q_log_prob = model.q_log_prob(params, z)                                         \n",
    "                        losses +=  (p_log_prob - q_log_prob)\n",
    "                    loss = losses/self.samples\n",
    "                    d_elbo /= self.samples\n",
    "                    step = adam.step(d_elbo)\n",
    "                    fparams += step                        \n",
    "                    self.F[f] =  -loss                \n",
    "\n",
    "                    stop = time.clock()\n",
    "                    self.time[f] = stop - start\n",
    "                    f+=1\n",
    "                if e % 10 == 0:\n",
    "                    pstate = 'Epoch = ' + \"{0:0=3d}\".format(e) + ': Loss = {0:.3f}'.format(self.F[f-1])\n",
    "                    print (pstate, end = '\\r')\n",
    "                    sys.stdout.flush()    \n",
    "                    \n",
    "                      \n",
    "        if algorithm == 'iSGD':\n",
    "            n = 1.  \n",
    "            z_old = [0.] * self.samples\n",
    "            grad_p_old = [0.] * self.samples\n",
    "            q_log_prob_old = [0.] * self.samples\n",
    "            p_log_prob_old = [0.] * self.samples\n",
    "            \n",
    "            for e in range(self.epochs):\n",
    "                for b in range(self.batches): \n",
    "                    start = time.clock()\n",
    "                    losses = 0.\n",
    "                    d_elbo = 0.\n",
    "                    idx = 0\n",
    "                    d_elbo = 0.\n",
    "                    params = unflatten(fparams)                \n",
    "                    if n > .7:\n",
    "                        for s in range(self.samples):\n",
    "                            z, eps = model.sample_q(params)\n",
    "                            p_log_prob = model.p_log_prob(idx, z)\n",
    "                            q_log_prob = model.q_log_prob(params, z)                                         \n",
    "                            grad_p = grad_p_log_prob(idx, z)\n",
    "                            g,_ =  flatten(model.grad_p(grad_p, eps, params))\n",
    "                            d_elbo += g                            \n",
    "                            losses +=  (p_log_prob - q_log_prob)\n",
    "\n",
    "                            z_old[s] = z\n",
    "                            grad_p_old[s] = grad_p\n",
    "                            q_log_prob_old[s] = q_log_prob                    \n",
    "                            p_log_prob_old[s] = p_log_prob                    \n",
    "                        loss = losses/self.samples\n",
    "                        d_elbo /= self.samples\n",
    "                    else:\n",
    "                        for s in range(self.samples):\n",
    "                            eps_ = model.calc_eps(z_old[s], params)\n",
    "                            q_log_prob = model.q_log_prob(params, z_old[s])          \n",
    "                            w = np.exp(q_log_prob - q_log_prob_old[s])            \n",
    "                            g,_ =  flatten(model.grad_p(grad_p_old[s], eps_, params, w))                                                        \n",
    "                            d_elbo += g                                                                             \n",
    "                            losses += w * (p_log_prob_old[s] - q_log_prob_old[s])\n",
    "                            print(w)\n",
    "                        loss = losses/self.samples\n",
    "                        d_elbo /= self.samples\n",
    "                    n = npr.uniform()\n",
    "                    step = adam.step(d_elbo)\n",
    "                    fparams += step                        \n",
    "                    self.F[f] =  -loss                \n",
    "                    stop = time.clock()\n",
    "                    self.time[f] = stop - start\n",
    "                    f+=1                    \n",
    "                if e % 10 == 0:\n",
    "                    pstate = 'Epoch = ' + \"{0:0=3d}\".format(e) + ': Loss = {0:.3f}'.format(self.F[f-1])\n",
    "                    print (pstate, end = '\\r')\n",
    "                    sys.stdout.flush()    \n",
    "        self.params = unflatten(fparams)                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19454733436Loss = 357267.504\n",
      "0.302299499613\n",
      "0.584107087922\n",
      "0.010519484819\n",
      "0.0177007706972\n",
      "6.22761155351e-05\n",
      "1.02643543746\n",
      "1.03152486251\n",
      "0.348082584022\n",
      "0.315641353596\n",
      "0.0337144071273\n",
      "3.075137682\n",
      "Epoch = 000: Loss = 357267.504\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9c44f285d0>]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD3CAYAAADlnNj/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c43f65190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 1000\n",
    "D = 10\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "samples = 2\n",
    "learning_rate = 0.1\n",
    "seed = 111\n",
    "npr.seed(seed)    \n",
    "data = 5 * npr.randn(N*D).reshape([N,D]) + 5\n",
    "    \n",
    "N = data.shape[0]\n",
    "D = data.shape[1]\n",
    "model = Normal(data)\n",
    "\n",
    "npr.seed(seed)    \n",
    "params = {}\n",
    "params['mu'] = {'mean': npr.randn(D), 'sigma': npr.randn(D)}\n",
    "params['tau'] = {'mean': npr.randn(D), 'sigma': npr.randn(D)}\n",
    "inference = Inference(model, params)\n",
    "inference.run(epochs, batch_size, samples, learning_rate, 'iSGD')\n",
    "plt.plot(np.cumsum(inference.time), -inference.F, color = colors[0])\n",
    "\n",
    "npr.seed(seed)    \n",
    "params = {}\n",
    "params['mu'] = {'mean': npr.randn(D), 'sigma': npr.randn(D)}\n",
    "params['tau'] = {'mean': npr.randn(D), 'sigma': npr.randn(D)}\n",
    "inference = Inference(model, params)\n",
    "inference.run(epochs, batch_size, samples, learning_rate, 'SGD')\n",
    "plt.plot(np.cumsum(inference.time), -inference.F, color = colors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': {'mean': array([ 2.72835394,  3.66311774,  2.93176504,  3.09556706,  2.64662772,\n",
       "          3.10960202,  3.52461212,  2.32655336,  2.11008444,  1.85147888,\n",
       "          3.94035004,  2.86698201,  2.06245394,  4.35876335,  1.94412672,\n",
       "          3.47194067,  3.85421854,  3.72306142,  4.63451564,  3.65039599,\n",
       "          2.25907414,  3.60213898,  2.54356548,  3.23259426,  4.08496976,\n",
       "          4.35343655,  2.07482833,  3.84533321,  2.9591534 ,  5.91711003,\n",
       "          5.03939222,  2.76739189,  2.5366043 ,  1.74741565,  3.89537939,\n",
       "          3.38170763,  3.25583235,  3.54871481,  1.96178938,  1.86216051,\n",
       "          1.36677891,  3.3051482 ,  1.93431633,  3.256536  ,  2.86369991,\n",
       "          4.67789688,  4.27107437,  4.5343567 ,  5.32274517,  2.40147979,\n",
       "          4.3516577 ,  1.97250106,  5.49562842,  2.52558732,  2.86654879,\n",
       "          4.04472133,  2.76173413,  4.56687311,  3.28399118,  3.04082795,\n",
       "          2.62193129,  0.90969842,  2.9687942 ,  3.203389  ,  2.67250603,\n",
       "          3.99003466,  3.54248994,  3.07307344,  1.67531494,  3.23255468,\n",
       "          4.12787456,  4.94041911,  3.91523229,  3.05905615,  3.53025497,\n",
       "          3.2265319 ,  2.85332715,  4.15636399,  3.73098519,  2.01721724,\n",
       "          3.27748136,  3.89902698,  2.68265585,  3.79836867,  4.67256638,\n",
       "          2.968522  ,  3.76333522,  2.86625412,  1.46975777,  2.25553392,\n",
       "          3.02414358,  4.08551018,  1.3224609 ,  3.29085879,  2.87388062,\n",
       "          5.51194967,  2.33882359,  3.14257927,  1.42917527,  2.36640982]),\n",
       "  'sigma': array([ 0.00548489, -0.60558884,  0.17537775, -1.29851772, -0.12157628,\n",
       "         -0.1221026 , -1.35541425, -1.45081156, -0.54833395, -0.47298165,\n",
       "          0.30411024,  0.76854629, -0.10911659, -1.94232375,  0.31063613,\n",
       "         -0.81170941, -1.2001222 ,  0.60724853,  0.05580187,  0.46835411,\n",
       "         -2.07298574,  0.06026554, -1.35309701, -0.25079732,  0.19100233,\n",
       "         -0.67988148, -0.69012564, -1.30161428, -1.00978811, -0.11759761,\n",
       "         -1.31353471,  0.34440219,  0.18085586,  0.42956101, -0.26829027,\n",
       "         -2.10696077, -0.36485731, -1.13974893, -1.84094733, -1.42630633,\n",
       "         -0.89847411, -0.05911579,  1.34827051, -0.17377486,  0.33449358,\n",
       "         -0.14009364, -1.57687251, -2.06446552, -1.02407456,  0.23861483,\n",
       "         -0.88196879,  0.08800833,  0.27581747, -0.06603684,  0.08569635,\n",
       "         -0.74423341, -1.00862955, -1.75571043, -0.51809554, -0.36544136,\n",
       "         -0.03595307,  0.88638422,  0.45379868, -0.63442017, -0.18484017,\n",
       "         -0.35915992, -2.5096226 , -0.53871107,  0.13067774, -0.10563734,\n",
       "          0.16460444, -0.40446654,  0.547583  ,  0.25380753, -0.54955012,\n",
       "         -0.1194257 , -1.05123082, -0.98976065, -0.54343753,  0.94882556,\n",
       "         -0.07530396,  1.07204061,  0.64027098,  0.08446247, -0.6387035 ,\n",
       "         -0.73529987, -1.04287717, -0.46274802,  0.37371123,  0.6466167 ,\n",
       "         -0.46916368, -1.60401418, -1.33144997, -0.68256591,  0.85717288,\n",
       "         -0.28184747, -0.15006683, -0.18677781, -2.61561122,  0.68960692])},\n",
       " 'tau': {'mean': array([-5.05423429, -4.33758148, -4.72383476, -3.14358399, -3.52877608,\n",
       "         -4.44930717, -3.44067176, -4.27523635, -4.10503446, -3.45494393,\n",
       "         -4.73379407, -4.23323239, -4.33229058, -3.02596281, -3.50575137,\n",
       "         -3.85050522, -3.49028699, -4.62075608, -3.12199205, -4.12790021,\n",
       "         -4.14965205, -3.84870494, -4.25675302, -3.39506531, -3.62861412,\n",
       "         -3.65491882, -4.59752921, -4.23924514, -3.32669785, -4.32637209,\n",
       "         -3.17845436, -3.95606363, -3.8379907 , -3.97959242, -4.70734623,\n",
       "         -4.02164404, -4.38290868, -4.73939889, -3.33993239, -3.21654295,\n",
       "         -3.65318954, -3.74818429, -4.0251619 , -3.82943989, -4.13047084,\n",
       "         -4.20655529, -3.56597488, -3.54049901, -4.57325481, -3.71603377,\n",
       "         -4.93618694, -4.05112883, -3.04824135, -4.3575794 , -2.88472958,\n",
       "         -3.57808162, -3.66383222, -4.06412379, -3.85240101, -2.9738427 ,\n",
       "         -3.9284091 , -4.07442758, -3.78165568, -4.20260761, -4.51049844,\n",
       "         -4.50924063, -4.0705274 , -3.72062813, -4.05728902, -3.60906588,\n",
       "         -3.77826571, -3.57380831, -3.57600594, -3.64204864, -3.1521975 ,\n",
       "         -3.66743448, -3.91412639, -3.68446299, -4.1415238 , -3.19689887,\n",
       "         -3.62502146, -2.72908672, -4.11490918, -3.45715359, -3.81005267,\n",
       "         -3.79959875, -4.26974492, -3.75357986, -3.96854617, -3.16568105,\n",
       "         -3.00726914, -3.72077487, -3.50020658, -3.88648149, -3.93137712,\n",
       "         -3.9742792 , -4.12571212, -3.54289857, -2.8369685 , -4.20572629]),\n",
       "  'sigma': array([-1.76870324, -1.28384797, -0.03886649, -1.56773124, -1.6629022 ,\n",
       "         -2.06065016, -1.31841855, -1.19188382, -0.99689738, -0.98915065,\n",
       "         -1.81370023, -1.17805407, -1.12629326, -2.08109201, -0.71181846,\n",
       "         -2.28993588, -1.32808821, -1.48408969, -0.88577358, -1.4930638 ,\n",
       "         -0.70898899, -1.93537683, -1.31224567, -1.35112719, -1.80827598,\n",
       "         -1.54399459, -1.3814001 , -2.12808746, -0.9690306 , -2.816152  ,\n",
       "         -2.2224828 , -1.63059951, -1.40156784, -1.74992422, -2.07060136,\n",
       "         -1.36101592, -0.81146553, -2.54809579, -1.76650917,  0.00714017,\n",
       "         -0.61010068, -1.27985804, -0.44782081, -1.96402913, -0.9786671 ,\n",
       "         -0.75676863, -2.40359924, -1.76273063, -1.34316452, -1.59016831,\n",
       "         -2.48810578, -0.3863036 , -0.66343544, -0.73798168, -1.44239629,\n",
       "         -2.57002756, -0.86476174, -1.78752739, -1.47971416, -1.51695818,\n",
       "         -1.1875866 , -1.18484038, -1.21109006, -1.28862497, -0.65531805,\n",
       "         -2.83138005, -1.70707417, -1.76630922, -0.82326907, -0.2469258 ,\n",
       "         -1.48250788, -1.82567926, -1.75242566, -1.52554694, -2.38915262,\n",
       "         -4.03150864, -0.79627273, -1.13198461, -2.25796506, -0.68936033,\n",
       "         -1.40256069, -1.25851084,  0.50957788, -1.52883389, -1.23222877,\n",
       "         -2.07624848, -2.82040644, -0.53049704, -0.25467066, -0.95752385,\n",
       "         -1.72218054,  0.00617204, -1.2992505 , -1.03599315, -1.33297258,\n",
       "         -2.57964019, -1.76307029, -1.29373201, -0.42509851, -1.12364961])}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.31082166,  7.74837187])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./np.sqrt(softplus(inference.params['tau']['mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
